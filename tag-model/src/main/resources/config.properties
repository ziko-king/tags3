# model config
tag.model.debug=true
hadoop.home.dir=D:/softs/developer/apache/hadoop-2.7.7
spark.debug.master=local[*]
tag.model.base.path=/apps/tags/model/
# profile table config
profile.hbase.table.name=tbl_profile
profile.hbase.table.family.user=user
profile.hbase.table.family.user.alias=u_
profile.hbase.table.family.user.col=userId
profile.hbase.table.family.item=item
profile.hbase.table.family.item.alias=i_
profile.hbase.table.family.item.col=itemId
# user && item commons qualifier
profile.hbase.table.family.common.col=tagIds
# mysql config
mysql.jdbc.driver=com.mysql.jdbc.Driver
mysql.jdbc.url=jdbc:mysql:///tags?useUnicode=true&characterEncoding=utf8&user=root&password=123456
mysql.jdbc.username=root
mysql.jdbc.password=123456
# hdfs config
fs.defaultFS=hdfs://192.168.10.20:8020
fs.user=hdfs
# datasource config
tag.spark.sql.hbase=cn.itcast.model.tools.spark.sql.HBaseSource
zookeeper.znode.parent=/hbase-unsecure
hbase.fs.tmp.dir=/tmp/hbase
hbaseTable=
family=
selectFields=
whereFields=
# zookeeper
zkHosts=192.168.10.20
zkPort=2181
# spark config
spark.master=yarn
spark.deploy.mode=cluster
spark.driver.memory=2g
spark.kryoserializer.buffer=64k
spark.kryoserializer.buffer.max=512k
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.warehouse.dir=
spark.sql.files.maxPartitionBytes=134217728
spark.sql.files.openCostInBytes=134217728
spark.sql.shuffle.partitions=600
spark.sql.autoBroadcastJoinThreshold=67108864
# solr config
solr.cloud.model=false
solr.addr=http://192.168.10.20:8983/solr/
solr.profile.family=user
solr.profile.fields=userId,tagIds
# oozie config
oozie.addr=http://192.168.10.20:11000/oozie
nameNode=hdfs://192.168.10.20:8020
jobTracker=192.168.10.20:8050
oozie.wf.application.path=hdfs://192.168.10.20:8020/apps/oozie/
user.name=oozie
oozie.use.system.libpath=true
jobTracker=bd001:8050
nameNode=hdfs://192.168.10.20:8020
shareLibKey=oozie.action.sharelib.for.spark
shareLibValue=spark2
master=yarn
oozie.libpath=
mainClass1=com.mengyao.graph.etl.apps.pc.jobs.saleanalysis.shop.shop.ShopSalesDayMergeApp
jarPath=hdfs://192.168.10.20:8020/etl/oozie/apps/data-graph-etl.jar
sparkOpts=--deploy-mode cluster --driver-memory 2G --executor-memory 4G --num-executors 2 --executor-cores 2


